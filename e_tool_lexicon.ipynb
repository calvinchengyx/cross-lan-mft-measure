{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "In this experiment, we tested the following approaches:\n",
    "1. local dictionary\n",
    "2. local dictionary + on multilingual word embeddings on unsupervised learning \n",
    "3. multilingual language models on supervised learning\n",
    "\n",
    "CMFD2 is saved in python package format [cmfd](https://pypi.org/project/cmfd/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.480 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# %pip install cmfd\n",
    "# %pip install jieba\n",
    "import pandas as pd\n",
    "import re\n",
    "import cmfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bm file to save the results\n",
    "bm = pd.read_csv('path to BM.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmfd2 - frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3087\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "df = pd.read_csv('path to BM.cs', dtype=str)\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# 2. Calculate the moral quantity of each text using the CMFD model\n",
    "for text in texts :\n",
    "    result = cmfd.moral_quantity(text, duplicate=False, with_word=True)\n",
    "    result_list.append(result)\n",
    "\n",
    "print(len(result_list))\n",
    "\n",
    "# 3. clean the result \n",
    "flattened_data_list = []\n",
    "for result in result_list:\n",
    "    flattened_data = {}\n",
    "    if result is None:\n",
    "        fixed_dict = {\n",
    "            ('altr',): {'num': 0.0, 'word': ''}, \n",
    "            ('auth',): {'num': 0.0, 'word': ''}, \n",
    "            ('care',): {'num': 0.0, 'word': ''}, \n",
    "            ('dili',): {'num': 0.0, 'word': ''}, \n",
    "            ('fair',): {'num': 0.0, 'word': ''}, \n",
    "            ('general',): {'num': 0.0, 'word': ''}, \n",
    "            ('libe',): {'num': 0.0, 'word': ''}, \n",
    "            ('loya',): {'num': 0.0, 'word': ''}, \n",
    "            ('mode',): {'num': 0.0, 'word': ''}, \n",
    "            ('resi',): {'num': 0.0, 'word': ''}, \n",
    "            ('sanc',): {'num': 0.0, 'word': ''}, \n",
    "            ('wast',): {'num': 0.0, 'word': ''}\n",
    "        }\n",
    "        for key, sub_dict in fixed_dict.items():\n",
    "            for sub_key, value in sub_dict.items():\n",
    "                new_key = f\"{key[0]}_{sub_key}\"\n",
    "                flattened_data[new_key] = value\n",
    "    else:\n",
    "        for key, sub_dict in result.items():\n",
    "            for sub_key, value in sub_dict.items():\n",
    "                new_key = f\"{key[0]}_{sub_key}\"\n",
    "                flattened_data[new_key] = value\n",
    "    flattened_data_list.append(flattened_data)\n",
    "        \n",
    "# # Convert the flattened dictionary to a DataFrame\n",
    "cmfd2 = pd.DataFrame(flattened_data_list)\n",
    "# add the original text column\n",
    "cmfd2['text'] = texts\n",
    "\n",
    "cmfd2_clean = cmfd2[['text', 'care_num', 'auth_num', 'fair_num', 'loya_num', 'sanc_num', 'care_word', 'auth_word', 'fair_word', 'loya_word', 'sanc_word','general_num', 'general_word']]\n",
    "new_column_names = {\n",
    "    'text': 'text',\n",
    "    'care_num': 'care',\n",
    "    'auth_num': 'auth',\n",
    "    'fair_num': 'fair',\n",
    "    'loya_num': 'loya',\n",
    "    'sanc_num': 'sanc',\n",
    "    'care_word': 'care_word',\n",
    "    'auth_word': 'auth_word',\n",
    "    'fair_word': 'fair_word',\n",
    "    'loya_word': 'loya_word',\n",
    "    'sanc_word': 'sanc_word',\n",
    "    'general_num': 'general_num',\n",
    "    'general_word': 'general_word'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "cmfd2_clean = cmfd2_clean.rename(columns=new_column_names)\n",
    "\n",
    "# Define the columns to check\n",
    "columns_to_check = ['care', 'auth', 'fair', 'loya', 'sanc']\n",
    "\n",
    "# Function to determine the value for the new column\n",
    "def determine_mfd2(row):\n",
    "    values = row[columns_to_check]\n",
    "    if values.max() == 0:\n",
    "        return \"non_moral\"\n",
    "    else:\n",
    "        max_value = values.max()\n",
    "        max_columns = [col for col in columns_to_check if row[col] == max_value]\n",
    "        return ', '.join(max_columns)\n",
    "\n",
    "# Apply the function to each row and create the new column\n",
    "bm['mfd2'] = cmfd2_clean.apply(determine_mfd2, axis=1)\n",
    "\n",
    "# save the result\n",
    "cmfd2_clean.to_csv('raw_result_cmfd2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmfd2 - multilingual word embeddings \n",
    "\n",
    "download the local language model from [fastText](https://fasttext.cc/docs/en/crawl-vectors.html) \n",
    "\n",
    "1. Each foundation (or \"concept\") is described by a list of keywords in C-MFD 2.0. \n",
    "2. The vector describing the concept is the average of all embeddings for these keywords.\n",
    "3. A document is transformed into a vector by tokenizing and averaging the embedding of these tokens. This is called the document embedding.\n",
    "4. To assess the relevance of a document with a concept, we consider the cosine similarity between their embeddings.\n",
    "\n",
    "code is adapted from Josh\n",
    "`python score_mf_ddr.py --data $DATA_DIR --text_col $TEXT_COL --verbose $VERBOSE --output $OUTPUT_FILE`\n",
    "\n",
    "Print progress: `VERBOSE=1`\n",
    "\n",
    "1. use the customized dictionary `customized.csv`\n",
    "2. code is running in the remote server for memory sake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "1. download `score_mf_ddr.py` from Josh's [repo](https://github.com/joshnguyen99/moral_axes/blob/main/scripts/utils/create_concepts.py)\n",
    "2. comment out line 5, and add `make_concepts_from_lexicon` function in line 31-79 from [`create_concepts.py`](https://github.com/joshnguyen99/moral_axes/blob/main/scripts/utils/create_concepts.py)\n",
    "3. revise line 25-27 to correctly read chinese embeddings model from FastText, with genism (this cost 2 hours to debug)\n",
    "4. add line 39-50 to load cmfd2 dictionary\n",
    "5. line 36, specify the tokenizer in spacy to Chinese\n",
    "6. line 116, removed to_lower() function \n",
    "7. save the revised document as `score_mf_ddr_revise.py`\n",
    "\n",
    "run the following code in the remote server\n",
    "`python3 score_mf_ddr_revise.py --data BM.csv --text_col text --verbose 1 --output raw_cmfd2_embedding.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cmfd 2 - multilingual word ebemddings + FrameAxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. prepared customized dataset `customized.csv`\n",
    "2. `main.py` change\n",
    "    1. add line 5 to load fasttext embedding data correctly \n",
    "    2. corresponding updated line 44\n",
    "    3. changed the file name to `frameaxis_main.py` to be more descriptive in the oii-server\n",
    "3. `frameaxis.py` change\n",
    "    1. add line 5 to load fasttext embedding data correctly, corresponding updated line 44\n",
    "    2. commented out line 9, 278, 279, no need to preprocess the data\n",
    "    3. update line 29, the dictionary path\n",
    "    4. added line 13-16 chinese spacy tokenizer, and update tokenizer in `doc_scores` function, all `split` to `tokenize`\n",
    "    5. when updating `tokenize` lines in step 4, removed its vocabulary filter on line 250, 267 accordingly\n",
    "    6. commented out line 298 to include NaN scores. \n",
    "    7. added progress bar code in line 264, and `from tqdm import tqdm` at line 4,  change the reporting frequency to every 100 documents in line 265\n",
    "\n",
    "run the following code in the remote server\n",
    "` python3 frameaxis_main.py --docs_colname text --input_file /BM.csv --output_file raw_result_cmfd2_frameaxis.csv --dict_type customized --word_embedding_model cc.zh.300.bin `\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmfd2 - multilingual contextual embeddings - FrameAxis\n",
    "- [?] do you have a local language dictionary?\n",
    "- [?] do you have a local language word embedding model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prepare dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misinfo/turing_dso_misinfo/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#### format the cmfd2.csv file to align with `mfd_original.csv` file\n",
    "cmfd = pd.read_csv('/cmfd2.csv')\n",
    "# only keep big-5 categories\n",
    "cmfd = cmfd[cmfd['category'].isin(['care', 'auth', 'fair', 'loya', 'sanc'])]\n",
    "\n",
    "# have to add a sentiment column for frame axis computation, used the \"liam168/c2-roberta-base-finetuned-dianping-chinese\" model for sentiment \n",
    "\n",
    "### load the model to add the sentiment layer\n",
    "from transformers import AutoModelForSequenceClassification , AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "ts_texts = cmfd['word'].tolist()\n",
    "model_name = \"liam168/c2-roberta-base-finetuned-dianping-chinese\"\n",
    "class_num = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=class_num)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "for i in range(len(ts_texts)):\n",
    "    sentiment_result = classifier(ts_texts[i])[0]\n",
    "    cmfd.loc[i, 'sentiment'] = sentiment_result['label']\n",
    "    cmfd.loc[i,'score'] =  sentiment_result['score']\n",
    "\n",
    "#### map the sentiment label to vice/virtue\n",
    "mapping = {\n",
    "    'positive': 'virtue',\n",
    "    'negative': 'vice'\n",
    "}\n",
    "cmfd['sentiment'] = cmfd['sentiment'].map(mapping)\n",
    "\n",
    "# save the result to customized\n",
    "cmfd.to_csv('customized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. revise the FrameAxis package to use xlm-roberta-base embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note\n",
    "- to run the frameAxis pacakge, i created a virtue environment on the server `conda create --name virtue python=3.10.14`\n",
    "- `conda activate virtue` to activate the environment\n",
    "- `pip install transformers torch scikit-learn` to install necessary packages, for multilingual word embeddings \n",
    "- changed `main.py`\n",
    "    - line 45-47, commmented out. \n",
    "    - added line 48-51, to download the model from pre-trained `FacebookAI/xlm-roberta-base` model \n",
    "    - changed line 55\n",
    "- changed `frameAxis.py`\n",
    "    - line 14-15, changed the model \n",
    "    - line 18, changed the class\n",
    "    - line 19-21, changed word embedding extraction methods \n",
    "    - line 74-77, define the new get embedding function \n",
    "    - other functions from `model[word]` to `get_embedding(word)` to get the embeddings\n",
    "    - line 96-97 to flatten the embeddings\n",
    "    - commented out/deleted line 48-71, line 133-171 useless for customized dictionary, \n",
    "    - commented out line 299, we don't preprocess the text, as the preprocess.py file is only for English text. \n",
    "    - moved line 21 and to line 40 to use cmfd2 dictionary as the microframe dictionary, not the pretrained googlenews embeddings\n",
    "    - continue checking: `def _compute_axes(self, mfd)` function is fine\n",
    "    - continue checking: find the bug, because line 273-278, `baseline_docs` and `tfidf` are all empty in the current setting. \n",
    "        - line 286 `doc_tokens` will return empty list, because it still tokenizes the text with english methods. \n",
    "        - so i added line 286 `doc_tokens_multilingual = self.tokenizer.tokenize(doc)` and revised line 287 `doc_tokens = [x for x in doc_tokens_multilingual if x in self.vocab]`\n",
    "    - contiue checking, worked out better but still 1/3 missing values. should not be like this based on this methods - so i deleted the filtering of the tokens in line 286 `doc_tokens = self.tokenizer.tokenize(doc)`. previously, the filtering was based on the english vocab, it wants to filter out the tokens in the document that are not in the `google-news-300` embedding models, but we don't have to do this for the multilingual embeddings. We tokenzie the text with the multilingual tokenizer, and keep them all for the similarity computation. \n",
    "    - optional: commented out line 324, depending on whether you want to keep NaN rows. \n",
    "    - added progress bar code in line 282, and `from tqdm import tqdm` at line 4\n",
    "    - change the reporting frequency to every 100 documents in line 283\n",
    "\n",
    "\n",
    "\n",
    "- run the command line `python main.py --docs_colname text --input_file /home/misinfo/turing_dso_misinfo/llms_mft_multilingual/paper_linked_final/datasets/BM.csv --output_file /home/misinfo/turing_dso_misinfo/llms_mft_multilingual/paper_linked_final/experiment_lan_tool/raw_result_cmfd2_frameaxis.csv --dict_type customized`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'source', 'source_lan', 'source_label', 'google_trans_en',\n",
      "       'source_dataset', 'care_score', 'fairness_score', 'loyalty_score',\n",
      "       'authority_score', 'sanctity_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cmfd2_sim = pd.read_csv('raw_result_cmfd2_fasttext.csv', index_col=0)\n",
    "print(cmfd2_sim.columns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bm = pd.read_csv('BM.csv')\n",
    "\n",
    "#### Function to determine the moral value for the text, based on the highest score (prob or freq) of the dictionary results\n",
    "def determine_score(row):\n",
    "    values = row[columns_to_check]\n",
    "    if values.max() == 0:\n",
    "        return \"non_moral\"\n",
    "    else:\n",
    "        max_value = values.max()\n",
    "        max_columns = [col for col in columns_to_check if row[col] == max_value]\n",
    "        return ', '.join(max_columns)\n",
    "\n",
    "# decide the score label for each text \n",
    "columns_to_check = ['care', 'auth', 'fair', 'loya', 'sanc']\n",
    "\n",
    "### Cleaning 1 - the CMFD2.0 python result\n",
    "# the result might include more than one labels for the classification \n",
    "cmfd2_freq = pd.read_csv('/raw_result_cmfd2_freq.csv')\n",
    "cmfd2_freq['freq_cmfd2'] = cmfd2_freq.apply(determine_score, axis=1)\n",
    "\n",
    "#append the result to the result datarame\n",
    "result_cmfd2 = pd.concat([bm, cmfd2_freq[['freq_cmfd2']]], axis=1)\n",
    "\n",
    "\n",
    "#### cleaning 2 - the CMFD2.0 Josh's simple word-embedding result, with word embedding\n",
    "cmfd2_sim = pd.read_csv('/raw_result_cmfd2_fasttext.csv')\n",
    "cmfd2_sim = cmfd2_sim[['text', 'care_score', 'fairness_score', 'loyalty_score', 'authority_score', 'sanctity_score']]\n",
    "new_column_names_cmfd2_sim = {\n",
    "    'text': 'text',\n",
    "    'care_score': 'care',\n",
    "    'fairness_score': 'fair',\n",
    "    'loyalty_score': 'loya',\n",
    "    'authority_score': 'auth',\n",
    "    'sanctity_score': 'sanc'\n",
    "}\n",
    "\n",
    "cmfd2_sim = cmfd2_sim.rename(columns=new_column_names_cmfd2_sim)\n",
    "cmfd2_sim[\"cc_cmfd2\"] = cmfd2_sim.apply(determine_score, axis=1)\n",
    "result_cmfd2 = pd.concat([result_cmfd2, cmfd2_sim[['cc_cmfd2']]], axis=1)\n",
    "\n",
    "\n",
    "#### Cleaning 3 - the CMFD2.0 frameAxis word-embedding result, with word embedding\n",
    "cmfd2_frameaxis_sim = pd.read_csv('/raw_result_cmfd2_fasttext_frameaxis.csv')\n",
    "cmfd2_frameaxis_sim = cmfd2_frameaxis_sim[['text', 'intensity_care', 'intensity_auth','intensity_fair', 'intensity_loya', 'intensity_sanc']]\n",
    "\n",
    "# only use intensity, intensity columns are results from FrameAxis, other columns are from the previous dictionaries\n",
    "new_column_names_cmfd2_frameaxis = {\n",
    "    'text': 'text',\n",
    "    'intensity_care': 'care',\n",
    "    'intensity_fair': 'fair',\n",
    "    'intensity_loya': 'loya',\n",
    "    'intensity_auth': 'auth',\n",
    "    'intensity_sanc': 'sanc'\n",
    "}\n",
    "\n",
    "cmfd2_frameaxis_sim = cmfd2_frameaxis_sim.rename(columns=new_column_names_cmfd2_frameaxis)\n",
    "cmfd2_frameaxis_sim['cc_frameaxis_cmfd2'] = cmfd2_frameaxis_sim.apply(determine_score, axis=1)\n",
    "result_cmfd2 = pd.concat([result_cmfd2, cmfd2_frameaxis_sim[['cc_frameaxis_cmfd2']]], axis=1)\n",
    "\n",
    "#### Cleaning 4 - the CMFD2.0 frameAxis contextual-embedding result, with xml embedding\n",
    "cmfd2_frameaxis_xml = pd.read_csv('raw_result_cmfd2_xml_frameaxis.csv')\n",
    "cmfd2_frameaxis_xml = cmfd2_frameaxis_xml[['text', 'intensity_care', 'intensity_auth','intensity_fair', 'intensity_loya', 'intensity_sanc']]\n",
    "cmfd2_frameaxis_xml = cmfd2_frameaxis_xml.rename(columns=new_column_names_cmfd2_frameaxis)\n",
    "cmfd2_frameaxis_xml['xml_frameaxis_cmfd2'] = cmfd2_frameaxis_xml.apply(determine_score, axis=1)\n",
    "result_cmfd2 = pd.concat([result_cmfd2, cmfd2_frameaxis_xml[['xml_frameaxis_cmfd2']]], axis=1)\n",
    "\n",
    "\n",
    "# save to csv \n",
    "result_cmfd2.to_csv('result_cmfd2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cmfd2 = pd.read_csv('result_cmfd2.csv')\n",
    "\n",
    "##### Define a function to deal with multiple matches for one document ######\n",
    "def multi_match_split(df, bm_column, predict_column):\n",
    "    \"\"\"\n",
    "    this function will generate two predicted results:\n",
    "    fuzzy match means it will be a match if there is at least one value matched in the prediction (more true values)\n",
    "    exact match means it will only be a match if the whole value is matched in the prediction (fewer true values)\n",
    "    for non-moral values, it will remain as \"non_moral\" and counted in the coverage calculation, but not in the F1 score calculation\n",
    "    \"\"\"\n",
    "    df[predict_column] = df[predict_column].fillna(\"non_moral\")\n",
    "\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        predict_value = row[predict_column]\n",
    "        bm_value = row[bm_column]\n",
    "        \n",
    "        # if No commas, meaning there is only one value predicted by the model, copy the value to both columns\n",
    "        if ',' not in predict_value:\n",
    "            df.loc[index, f\"{predict_column}_fuzzy_match\"] = predict_value\n",
    "            df.loc[index, f\"{predict_column}_exact_match\"] = predict_value\n",
    "        else:\n",
    "            \n",
    "            # Multiple values, split by comma\n",
    "            predict_value = predict_value.split(',')\n",
    "\n",
    "            # very unlikely for the model to code a text to non-moral and moral values at the same time, but just in case\n",
    "            if \"non_moral\" in predict_value:\n",
    "                df.loc[index, f\"{predict_column}_fuzzy_match\"] = \"non_moral\"\n",
    "                df.loc[index, f\"{predict_column}_exact_match\"] = \"non_moral\"\n",
    "            else:  \n",
    "                if bm_value in predict_value:\n",
    "                    # If source_label is in the mfd values - it is a match\n",
    "                    df.loc[index, f\"{predict_column}_fuzzy_match\"] = bm_value\n",
    "                    # Select one of the other values\n",
    "                    exact_match_value = next((val for val in predict_value if val != bm_value))\n",
    "                    df.loc[index, f\"{predict_column}_exact_match\"] = exact_match_value\n",
    "                else:\n",
    "                    # If no match is found, select the first value for both columns\n",
    "                    df.loc[index, f\"{predict_column}_exact_match\"] = predict_value[0]\n",
    "                    df.loc[index, f\"{predict_column}_fuzzy_match\"] = predict_value[0]\n",
    "    # trim the spaces before and after the string in the columns\n",
    "    df.loc[:,f\"{predict_column}_exact_match\"] = df[f\"{predict_column}_exact_match\"].str.strip()\n",
    "    df.loc[:,f\"{predict_column}_fuzzy_match\"] = df[f\"{predict_column}_fuzzy_match\"].str.strip()\n",
    "    # df[f\"{predict_column}\"] = df[f\"{predict_column}\"].str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "##### Define a function to calculate model performance ######\n",
    "\n",
    "def model_performance_coverage(df, predicted_label_column):\n",
    "    \"\"\"\n",
    "    This function will calculate the coverage of the model performance\n",
    "    coverage is the percentage of the non-moral text predicted by the model, meaning the limitation of the model performance\n",
    "    \"\"\"\n",
    "    # non_moral label is the label for the non-moral text\n",
    "    non_moral_label = \"non_moral\"\n",
    "    value_counts = df[predicted_label_column].value_counts()\n",
    "    non_moral_count = value_counts.get(non_moral_label, 0)\n",
    "    # show the percentage of the coverage\n",
    "    coverage = (len(df) - non_moral_count) / len(df)\n",
    "    # keep 4 digits after the decimal point\n",
    "    coverage = round(coverage, 2)\n",
    "\n",
    "    return coverage\n",
    "\n",
    "#### Function to round the values in the classification report dictionary #####\n",
    "def round_classification_report(report, digits=3):\n",
    "    for key, value in report.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                report[key][sub_key] = round(sub_value, digits)\n",
    "        else:\n",
    "            report[key] = round(value, digits)\n",
    "    return report\n",
    "\n",
    "\n",
    "def model_performance(df, source_label_column, predicted_label_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will return a dataframe, containing the classification report, model's name and coverage figure\n",
    "    \"\"\"\n",
    "    # calculate the coverage of the model\n",
    "    model_coverage = model_performance_coverage(df, predicted_label_column)\n",
    "    \n",
    "    # then, remove non-moral values from the classification report as it is calculated in the coverage calculation\n",
    "    df = df[df[predicted_label_column]!='non_moral']\n",
    "    true_labels = df[source_label_column]\n",
    "    predicted_labels = df[predicted_label_column]\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(true_labels, predicted_labels, output_dict=True, zero_division=0)\n",
    "    rounded_class_report = round_classification_report(class_report, digits=2)\n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(rounded_class_report)\n",
    "    report_df = report_df.loc[['f1-score']]\n",
    "    report_df = report_df.rename(index={'f1-score': f'f1 {predicted_label_column}'})\n",
    "    \n",
    "    # add coverage figure to a new column, so far there should be only one row in the dataframe\n",
    "    report_df['model_coverage'] = model_coverage\n",
    "    return report_df\n",
    "\n",
    "######## ADD the random baseline to each benchmark dataset ########\n",
    "    # Ground truth label distribution\n",
    "label_BM_MFV = pd.Series({'care': 27,'auth': 25, 'loya': 16, 'fair': 12,'sanc': 10})\n",
    "label_BM_CS =  pd.Series({'care': 389,'auth': 331, 'loya': 248, 'fair': 259,'sanc': 226})\n",
    "label_BM_CV = pd.Series({'care': 619,'auth': 271, 'loya': 349, 'fair': 253,'sanc': 52})\n",
    "\n",
    "def randome_baseline_performance(source_dataset):\n",
    "    label_counts_str = f\"label_{source_dataset}\"\n",
    "    \n",
    "    label_counts = eval(label_counts_str)\n",
    "    total_samples = label_counts.sum()\n",
    "\n",
    "    # Initialize an empty list to store random classification reports\n",
    "    classification_reports = []\n",
    "\n",
    "    classification_reports = []\n",
    "    for _ in range(1000):\n",
    "            random_predictions = np.random.choice(label_counts.index, size=total_samples, p=label_counts / total_samples)\n",
    "            true_labels = np.repeat(label_counts.index, label_counts.values)\n",
    "            \n",
    "            # Generate classification report for random predictions\n",
    "            random_classification_report = classification_report(true_labels, random_predictions, output_dict=True, zero_division=0)\n",
    "            # # classification_reports.append(random_classification_report)\n",
    "            # ramdom_rounded_class_report = round_classification_report(random_classification_report, digits=2)\n",
    "            random_report_df = pd.DataFrame(random_classification_report)\n",
    "            # extract all keys and its corresponding 'f1-score' values if it has otherwise, any value\n",
    "            extracted_values = {key: (value['f1-score'] if isinstance(value, dict) and 'f1-score' in value else value)\n",
    "                        for key, value in random_classification_report.items()}\n",
    "\n",
    "            classification_reports.append(extracted_values)\n",
    "\n",
    "        # Average the classification reports\n",
    "    classification_reports_df = pd.DataFrame(classification_reports)\n",
    "\n",
    "    # calculate the average of each column in the dataframe\n",
    "    avg_random_report = classification_reports_df.mean().to_frame().T\n",
    "    random_report_df = avg_random_report.rename(index={0: 'f1 random baseline'})\n",
    "    random_report_df[\"model_coverage\"] = 1.00\n",
    "\n",
    "    # Convert classification report to DataFrame\n",
    "    random_report_df = round_classification_report(random_report_df, digits=2)\n",
    "    \n",
    "    return random_report_df\n",
    "\n",
    "###### specify models we want to benchmark and compare ######\n",
    "local_lexicon_models = ['freq_cmfd2', 'cc_cmfd2', 'cc_frameaxis_cmfd2','xml_frameaxis_cmfd2']\n",
    "\n",
    "####### define a function to present the results in a table #######\n",
    "def present_tables_by_BM(df, source_dataset):\n",
    "    df = df[df['source_dataset'] == source_dataset]\n",
    "\n",
    "    table_display = pd.DataFrame()\n",
    "    # add the ramdom baseline to the table\n",
    "    random_baseline = randome_baseline_performance(source_dataset)\n",
    "    table_display = pd.concat([table_display, random_baseline], axis=0) # row bind\n",
    "    \n",
    "    for model_column in local_lexicon_models:\n",
    "        df =  multi_match_split(df, 'source_label', model_column)\n",
    "        df_row = model_performance(df, 'source_label', f'{model_column}_fuzzy_match')\n",
    "        table_display = pd.concat([table_display, df_row], axis=0) # row bind\n",
    "    \n",
    "    print(f\"Machine Translation MF Measurement Results Benchmarked with {source_dataset} Dataset\")\n",
    "    display(table_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Translation MF Measurement Results Benchmarked with BM_MFV Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth</th>\n",
       "      <th>care</th>\n",
       "      <th>fair</th>\n",
       "      <th>loya</th>\n",
       "      <th>sanc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>model_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1 random baseline</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 freq_cmfd2_fuzzy_match</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_cmfd2_fuzzy_match</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 xml_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    auth  care  fair  loya  sanc  accuracy  \\\n",
       "f1 random baseline                  0.16  0.25  0.16  0.34  0.10      0.21   \n",
       "f1 freq_cmfd2_fuzzy_match           0.48  0.18  0.67  0.29  0.22      0.39   \n",
       "f1 cc_cmfd2_fuzzy_match             0.44  0.00  0.00  0.12  0.18      0.30   \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match   0.08  0.00  0.00  0.30  0.00      0.19   \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match  0.00  0.07  0.24  0.12  0.00      0.16   \n",
       "\n",
       "                                    macro avg  weighted avg  model_coverage  \n",
       "f1 random baseline                       0.20          0.21             1.0  \n",
       "f1 freq_cmfd2_fuzzy_match                0.37          0.42             0.4  \n",
       "f1 cc_cmfd2_fuzzy_match                  0.15          0.16             1.0  \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match        0.08          0.08             1.0  \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match       0.09          0.07             1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "present_tables_by_BM(result_cmfd2, 'BM_MFV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Translation MF Measurement Results Benchmarked with BM_CS Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth</th>\n",
       "      <th>care</th>\n",
       "      <th>fair</th>\n",
       "      <th>loya</th>\n",
       "      <th>sanc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>model_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1 random baseline</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 freq_cmfd2_fuzzy_match</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_cmfd2_fuzzy_match</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 xml_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    auth  care  fair  loya  sanc  accuracy  \\\n",
       "f1 random baseline                  0.22  0.26  0.17  0.19  0.17      0.21   \n",
       "f1 freq_cmfd2_fuzzy_match           0.74  0.76  0.73  0.68  0.74      0.74   \n",
       "f1 cc_cmfd2_fuzzy_match             0.44  0.32  0.35  0.39  0.37      0.39   \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match   0.14  0.05  0.15  0.29  0.02      0.20   \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match  0.00  0.14  0.30  0.00  0.00      0.19   \n",
       "\n",
       "                                    macro avg  weighted avg  model_coverage  \n",
       "f1 random baseline                       0.20          0.21            1.00  \n",
       "f1 freq_cmfd2_fuzzy_match                0.73          0.73            0.76  \n",
       "f1 cc_cmfd2_fuzzy_match                  0.37          0.37            0.97  \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match        0.13          0.12            0.97  \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match       0.09          0.09            1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "present_tables_by_BM(result_cmfd2, 'BM_CS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Translation MF Measurement Results Benchmarked with BM_CV Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth</th>\n",
       "      <th>care</th>\n",
       "      <th>fair</th>\n",
       "      <th>loya</th>\n",
       "      <th>sanc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>model_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1 random baseline</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 freq_cmfd2_fuzzy_match</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_cmfd2_fuzzy_match</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 cc_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 xml_frameaxis_cmfd2_fuzzy_match</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    auth  care  fair  loya  sanc  accuracy  \\\n",
       "f1 random baseline                  0.19  0.42  0.16  0.25  0.04      0.28   \n",
       "f1 freq_cmfd2_fuzzy_match           0.26  0.63  0.45  0.28  0.09      0.45   \n",
       "f1 cc_cmfd2_fuzzy_match             0.28  0.17  0.09  0.01  0.03      0.20   \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match   0.02  0.03  0.04  0.37  0.00      0.23   \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match  0.00  0.18  0.27  0.02  0.00      0.19   \n",
       "\n",
       "                                    macro avg  weighted avg  model_coverage  \n",
       "f1 random baseline                       0.21          0.28            1.00  \n",
       "f1 freq_cmfd2_fuzzy_match                0.34          0.43            0.64  \n",
       "f1 cc_cmfd2_fuzzy_match                  0.12          0.13            0.98  \n",
       "f1 cc_frameaxis_cmfd2_fuzzy_match        0.09          0.10            0.98  \n",
       "f1 xml_frameaxis_cmfd2_fuzzy_match       0.09          0.12            1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "present_tables_by_BM(result_cmfd2, 'BM_CV')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
